{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "(before Multinomial logistic regression)\n",
    "We want to predict the probability of an input belonging to one of two classes.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Study case : \n",
    "Perform logisitc regression to classify the cats and dogs dataset.\n",
    "\n",
    "http://cs229.stanford.edu/notes/cs229-notes1.pdf p.16\n",
    "#### a) Dataset\n",
    "- Input : Images of size ?? where a cat or a dog is present\n",
    "- Output : 0 if the input is a cat, 1 otherwise\n",
    "\n",
    "#### b) Classifier\n",
    "Logistic regression in 3 steps :\n",
    "- p = exp(W^t X + b)\n",
    "- C = - y.ln(p) - (1-y)(ln(1-p))\n",
    "- Gradient descent ^^"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset !\n",
    "- Load it\n",
    "- check it\n",
    "- quick\n",
    "- rewrite it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download the cats vs dogs dataset\n",
    "# From here https://www.kaggle.com/c/dogs-vs-cats/data\n",
    "# Move the train.zip file here\n",
    "!unzip train.zip -d ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/skimage/transform/_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nyBSZX4hMkfmFyBSZX4hMkfmFyJT/A1b4DDsylki6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7a2a5c4790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "\n",
    "IMG_SIZE = 30  # width of the squared resized images\n",
    "\n",
    "\n",
    "def read_img(img_path, as_vector=True):\n",
    "    img = imread(img_path)\n",
    "    img = resize(img, [IMG_SIZE, IMG_SIZE])\n",
    "    img = img.sum(axis=2)\n",
    "    if as_vector is True:\n",
    "        img = img.reshape(-1)\n",
    "    return img\n",
    "\n",
    "\n",
    "def batch_generator(batch_size=10):\n",
    "    while True:\n",
    "        db = os.listdir(\"./train\")\n",
    "        random.shuffle(db)\n",
    "        batch_x = np.zeros((batch_size, IMG_SIZE * IMG_SIZE))\n",
    "        batch_y = np.zeros((batch_size,))\n",
    "        for _ in range(len(db) / batch_size):  # new batch\n",
    "            for i in range(batch_size): # fill the batch\n",
    "                img_name = db.pop()\n",
    "                batch_x[i] = read_img(\"./train/\" + img_name)\n",
    "                batch_y[i] = 0 if img_name[:3] == 'dog' else 1\n",
    "            yield batch_x, batch_y\n",
    "\n",
    "img = read_img('./train/dog.5507.jpg', as_vector=False)\n",
    "plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train\n",
    "- Cross it\n",
    "- crack it\n",
    "- switch\n",
    "- update it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gen = batch_generator(1)\n",
    "valid_gen = batch_generator(100)\n",
    "X_valid, Y_valid = valid_gen.next()\n",
    "\n",
    "W = np.random.normal(size=IMG_SIZE * IMG_SIZE)\n",
    "b = np.random.normal()\n",
    "\n",
    "log = lambda x: np.log(x + 1e-8)\n",
    "exp = lambda x: np.exp(x + 1e-8)\n",
    "\n",
    "alph_ = 1.6732632423543772848170429916717\n",
    "lambd_ = 1.0507009873554804934193349852946\n",
    "linear = lambda x: np.dot(W.T, x) + b\n",
    "sigm = lambda x: 1 / (1 + exp(-x))\n",
    "elu = lambda x, alpha: np.maximum(x, alpha * (exp(x) - 1))\n",
    "selu = lambda x: lambd_ * elu(x, alph_)\n",
    "nll = lambda p, y: - y * log(p) - (1 - y) * log(1 - p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-59975f2788cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0m_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mgradient_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": [
    "def prob(X):\n",
    "    return sigm(linear(X))\n",
    "\n",
    "\n",
    "def loss(X, y):\n",
    "    # loss = -   y .ln(  sigm(WT.X+b))\n",
    "    #        -(1-y).ln(1-sigm(WT.X+b))\n",
    "    p = prob(X)\n",
    "    return nll(p, y)\n",
    "\n",
    "\n",
    "def gradient_loss(X, y):\n",
    "    # d.loss / d.W = (p-y).X\n",
    "    p = prob(X)\n",
    "    return ((p - y) * X)\n",
    "\n",
    "\n",
    "def evaluate():\n",
    "    probs = np.array(map(prob, X_valid))\n",
    "    loss = nll(probs, Y_valid)\n",
    "    loss = loss.mean()\n",
    "    probs = map(round, probs)\n",
    "    accuracy = sum(probs == Y_valid)\n",
    "    return accuracy, loss\n",
    "    \n",
    "\n",
    "losses = []\n",
    "alpha = 0.001\n",
    "for epoch in range(60):\n",
    "    _loss = 0\n",
    "    alpha *= 0.95\n",
    "    for _ in range(2000):\n",
    "        X, Y = gen.next()\n",
    "        X, Y = X[0], Y[0]\n",
    "        _loss += loss(X, Y) \n",
    "        W = W - alpha * gradient_loss(X, Y)\n",
    "    losses.append(_loss / 2000)\n",
    "    print epoch, losses[-1], evaluate(), alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def prob(X):\n",
    "    return sigm(selu(linear(X)))\n",
    "\n",
    "\n",
    "def loss(X, y):\n",
    "    # loss = -   y .ln(  sigm(WT.X+b))\n",
    "    #        -(1-y).ln(1-sigm(WT.X+b))\n",
    "    p = prob(X)\n",
    "    return nll(p, y)\n",
    "\n",
    "\n",
    "def gradient_loss(X, y):\n",
    "    # d.loss / d.W = (p-y).X\n",
    "    p = prob(X)\n",
    "    if linear(X) <= 0:\n",
    "        return X * (p - y) * (p + lambd_ * lambd_)\n",
    "    else: \n",
    "        return X * (p - y) * lambd_\n",
    "\n",
    "\n",
    "def evaluate():\n",
    "    probs = np.array(map(prob, X_valid))\n",
    "    loss = nll(probs, Y_valid)\n",
    "    loss = loss.mean()\n",
    "    probs = map(round, probs)\n",
    "    accuracy = sum(probs == Y_valid)\n",
    "    return accuracy, loss\n",
    "    \n",
    "\n",
    "losses = []\n",
    "alpha = 0.001\n",
    "for epoch in range(30):\n",
    "    _loss = 0\n",
    "    alpha *= 0.95\n",
    "    for _ in range(2000):\n",
    "        X, Y = gen.next()\n",
    "        X, Y = X[0], Y[0]\n",
    "        _loss += loss(X, y)\n",
    "        W = W - alpha * gradient_loss(X, Y)\n",
    "    losses.append(_loss / 2000)\n",
    "    print epoch, losses[-1], evaluate(), alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
