{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "(before Multinomial logistic regression)\n",
    "We want to predict the probability of an input belonging to one of two classes.\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Study case : \n",
    "Classify the zero and one digits from MNist dataset \n",
    "\n",
    "#### a) Dataset\n",
    "- Input : Images of size 28*28 where a one or two is present\n",
    "- Output : 0 if the input is a 0, 1 otherwise\n",
    "\n",
    "#### b) Classifier\n",
    "We use a logistic regression, \n",
    "(You may want to read this : http://cs229.stanford.edu/notes/cs229-notes1.pdf) :\n",
    "- s = (W^t . X + b)\n",
    "- p = 1 / (1 + exp(-s))\n",
    "- C = - y.ln(p) - (1-y)(ln(1-p))\n",
    "- Gradient descent ^^\n",
    "\n",
    "To use gradient descent, we have to compute the gradient of the cost with respect to w : dC/dW.\n",
    "We take adventage of the chain rule :\n",
    "- dC/dW\n",
    "- = dC/dp . dp/ds . ds/dW \n",
    "\n",
    "We derive each terms :\n",
    "dC/dp\n",
    "- dC/dp = - y/p - (-1)(1-y)/(1-p)\n",
    "- = - y/p + (1-y)/(1-p)\n",
    "- = (-y + y.p + p - y.p) / p(1-p)\n",
    "- = (-y+p) / p(1-p)\n",
    "\n",
    "dp/ds :\n",
    "- dp/ds = -(-exp(-s)) / (1 + exp(-s)) \n",
    "- = -(-exp(-s)) / (1 + exp(-s))\n",
    "- = (exp(-s) + 1 - 1) / (1 + exp(-s))^2\n",
    "- = (exp(-s) + 1) / (1 + exp(-s))^2 - 1 / (1 + exp(-s))^2\n",
    "- = 1 / (1 + exp(-s)) - (1 / (1 + exp(-s)))^2\n",
    "- = p - p^2\n",
    "- = p(1-p)\n",
    "\n",
    "ds/dw :\n",
    "- ds/dw = x\n",
    "\n",
    "All together, we have :\n",
    "- dC/dW\n",
    "- = dC/dp . dp/ds . ds/dW \n",
    "- (-y+p) / p(1-p) . p(1-p) . x\n",
    "- (-y+p) . x\n",
    "- (p-y) . x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.715436241611 0.530715691748\n",
      "0.776865377023 0.44750746739\n",
      "0.791630477694 0.41759199575\n",
      "0.799921042242 0.399926379371\n",
      "0.803395183577 0.387860727491\n",
      "0.80757994473 0.378971782468\n",
      "0.808922226609 0.372098490189\n",
      "0.8098697197 0.366595614948\n",
      "0.810738255034 0.362071465545\n",
      "0.811369917094 0.358273630921\n",
      "0.812396367943 0.355031608003\n",
      "0.812870114489 0.352225681601\n",
      "0.813580734307 0.349769064664\n",
      "0.814291354126 0.347597138532\n",
      "0.814370311883 0.345660692732\n",
      "0.814212396368 0.343921521398\n",
      "0.814607185156 0.342349463965\n",
      "0.814923016186 0.340920361981\n",
      "0.815317804974 0.33961461483\n",
      "0.81579155152 0.338416137499\n",
      "0.815712593762 0.337311594632\n",
      "0.81579155152 0.336289828425\n",
      "0.81579155152 0.335341425036\n",
      "0.815870509278 0.334458381626\n",
      "0.816028424793 0.333633847616\n",
      "0.815870509278 0.332861921414\n",
      "0.815949467035 0.332137489121\n",
      "0.815870509278 0.331456095375\n",
      "0.815870509278 0.330813839047\n",
      "0.815870509278 0.330207288347\n",
      "0.815949467035 0.329633411222\n",
      "0.816186340308 0.329089517919\n",
      "0.816344255823 0.328573213255\n",
      "0.816581129096 0.328082356758\n",
      "0.816660086854 0.327615029163\n",
      "0.816818002369 0.327169504116\n",
      "0.817133833399 0.326744224167\n",
      "0.817212791157 0.326337780289\n",
      "0.817291748914 0.325948894341\n",
      "0.817528622187 0.325576403986\n",
      "0.817528622187 0.325219249674\n",
      "0.817607579945 0.324876463351\n",
      "0.817607579945 0.324547158649\n",
      "0.817686537702 0.32423052232\n",
      "0.81776549546 0.32392580674\n",
      "0.817844453218 0.323632323326\n",
      "0.817923410975 0.323349436734\n",
      "0.817923410975 0.323076559742\n",
      "0.81808132649 0.322813148714\n",
      "0.818397157521 0.322558699573\n",
      "0.818555073036 0.322312744218\n",
      "0.818555073036 0.322074847327\n",
      "0.818634030794 0.321844603502\n",
      "0.818712988551 0.321621634703\n",
      "0.818791946309 0.321405587949\n",
      "0.818712988551 0.321196133252\n",
      "0.818712988551 0.320992961748\n",
      "0.818712988551 0.320795784013\n",
      "0.818634030794 0.320604328537\n",
      "0.818634030794 0.320418340344\n",
      "0.818634030794 0.320237579737\n",
      "0.818555073036 0.320061821154\n",
      "0.818397157521 0.319890852132\n",
      "0.818397157521 0.319724472355\n",
      "0.818555073036 0.319562492791\n",
      "0.818634030794 0.319404734898\n",
      "0.818634030794 0.319251029897\n",
      "0.818634030794 0.319101218109\n",
      "0.818634030794 0.318955148337\n",
      "0.818712988551 0.318812677309\n",
      "0.818712988551 0.318673669159\n",
      "0.818712988551 0.318537994944\n",
      "0.818712988551 0.31840553221\n",
      "0.818712988551 0.31827616458\n",
      "0.818712988551 0.318149781378\n",
      "0.818712988551 0.318026277281\n",
      "0.818791946309 0.317905551994\n",
      "0.818870904066 0.31778750995\n",
      "0.818949861824 0.317672060032\n",
      "0.818949861824 0.317559115314\n",
      "0.819028819582 0.317448592817\n",
      "0.819028819582 0.317340413289\n",
      "0.818949861824 0.31723450099\n",
      "0.819028819582 0.317130783502\n",
      "0.819107777339 0.317029191543\n",
      "0.819186735097 0.316929658797\n",
      "0.819186735097 0.316832121756\n",
      "0.819186735097 0.316736519571\n",
      "0.819107777339 0.316642793909\n",
      "0.819186735097 0.316550888826\n",
      "0.819186735097 0.316460750643\n",
      "0.819186735097 0.316372327827\n",
      "0.819186735097 0.316285570889\n",
      "0.819265692854 0.316200432277\n",
      "0.819265692854 0.316116866284\n",
      "0.819265692854 0.316034828954\n",
      "0.819344650612 0.315954278001\n",
      "0.819344650612 0.315875172726\n",
      "0.819344650612 0.315797473945\n",
      "0.819344650612 0.315721143914\n",
      "0.819344650612 0.315646146264\n",
      "0.81942360837 0.315572445938\n",
      "0.81942360837 0.315500009132\n",
      "0.81942360837 0.315428803234\n",
      "0.81942360837 0.315358796774\n",
      "0.819502566127 0.315289959375\n",
      "0.819502566127 0.315222261701\n",
      "0.819344650612 0.315155675413\n",
      "0.81942360837 0.315090173127\n",
      "0.819502566127 0.315025728371\n",
      "0.819502566127 0.314962315551\n",
      "0.819502566127 0.314899909906\n",
      "0.819502566127 0.314838487482\n",
      "0.819502566127 0.314778025091\n",
      "0.819581523885 0.314718500287\n",
      "0.819660481642 0.314659891329\n",
      "0.819660481642 0.314602177158\n",
      "0.819660481642 0.314545337364\n",
      "0.819660481642 0.314489352168\n",
      "0.819581523885 0.314434202389\n",
      "0.819581523885 0.314379869427\n",
      "0.819660481642 0.314326335237\n",
      "0.819581523885 0.31427358231\n",
      "0.819581523885 0.314221593649\n",
      "0.819581523885 0.314170352754\n",
      "0.819581523885 0.314119843601\n",
      "0.819581523885 0.314070050624\n",
      "0.819581523885 0.3140209587\n",
      "0.819581523885 0.31397255313\n",
      "0.819581523885 0.313924819626\n",
      "0.819660481642 0.313877744295\n",
      "0.819660481642 0.313831313626\n",
      "0.819581523885 0.313785514473\n",
      "0.819581523885 0.313740334047\n",
      "0.819581523885 0.313695759899\n",
      "0.819581523885 0.313651779911\n",
      "0.819581523885 0.313608382285\n",
      "0.819581523885 0.313565555527\n",
      "0.819581523885 0.313523288442\n",
      "0.819502566127 0.313481570122\n",
      "0.819502566127 0.313440389935\n",
      "0.819502566127 0.313399737519\n",
      "0.819502566127 0.313359602767\n",
      "0.819502566127 0.313319975826\n",
      "0.819581523885 0.313280847081\n",
      "0.819581523885 0.313242207153\n",
      "0.819581523885 0.313204046888\n",
      "0.819660481642 0.313166357351\n",
      "0.819660481642 0.313129129819\n",
      "0.8197394394 0.313092355772\n",
      "0.8197394394 0.313056026889\n",
      "0.8197394394 0.31302013504\n",
      "0.8197394394 0.312984672279\n",
      "0.8197394394 0.312949630842\n",
      "0.8197394394 0.312915003137\n",
      "0.8197394394 0.31288078174\n",
      "0.8197394394 0.312846959389\n",
      "0.8197394394 0.312813528982\n",
      "0.8197394394 0.312780483566\n",
      "0.8197394394 0.312747816339\n",
      "0.8197394394 0.31271552064\n",
      "0.819818397158 0.312683589947\n",
      "0.819818397158 0.312652017875\n",
      "0.819818397158 0.312620798165\n",
      "0.819818397158 0.312589924687\n",
      "0.819818397158 0.312559391434\n",
      "0.819818397158 0.312529192515\n",
      "0.819818397158 0.312499322157\n",
      "0.819818397158 0.312469774698\n",
      "0.819818397158 0.312440544584\n",
      "0.819818397158 0.312411626367\n",
      "0.819818397158 0.312383014702\n",
      "0.819818397158 0.312354704344\n",
      "0.819818397158 0.312326690144\n",
      "0.819897354915 0.312298967049\n",
      "0.819897354915 0.312271530098\n",
      "0.819897354915 0.312244374419\n",
      "0.819897354915 0.31221749523\n",
      "0.819897354915 0.312190887832\n",
      "0.819897354915 0.312164547613\n",
      "0.819897354915 0.312138470043\n",
      "0.819897354915 0.312112650672\n",
      "0.819897354915 0.312087085131\n",
      "0.819897354915 0.312061769127\n",
      "0.819897354915 0.312036698448\n",
      "0.819897354915 0.312011868955\n",
      "0.819976312673 0.311987276586\n",
      "0.819976312673 0.311962917353\n",
      "0.819976312673 0.311938787344\n",
      "0.819976312673 0.311914882719\n",
      "0.819976312673 0.31189119971\n",
      "0.819976312673 0.311867734625\n",
      "0.82005527043 0.311844483844\n",
      "0.819976312673 0.311821443817\n",
      "0.819976312673 0.311798611071\n",
      "0.819976312673 0.311775982201\n",
      "0.819976312673 0.311753553879\n",
      "0.819976312673 0.311731322847\n",
      "0.819976312673 0.311709285921\n",
      "0.819976312673 0.31168743999\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import utils\n",
    "reload(utils)\n",
    "from utils import *\n",
    "\n",
    "\n",
    "# Get the input data\n",
    "(x, y), (x_, y_) = keras.datasets.mnist.load_data()\n",
    "X = x[np.where(y<=1)]\n",
    "X = X.reshape(X.shape[0], -1)  # 2D image to 1D\n",
    "X = X / 255  # Normalize inputs\n",
    "Y = y[np.where(y<=1)]\n",
    "Y = np.array(Y, dtype='int')\n",
    "\n",
    "# Set-up the weights\n",
    "W = np.random.random((784,))-.5\n",
    "\n",
    "\n",
    "# Train\n",
    "for _ in range(200):\n",
    "    acc = []\n",
    "    losses = []\n",
    "    for x,y in zip(X, Y):\n",
    "        pred = linear(x, W)\n",
    "        pred = sigmoid(pred)\n",
    "        acc.append(round(pred)==y)\n",
    "        loss = nll(pred, y)\n",
    "        losses.append(loss)\n",
    "        update = (pred - y) * x \n",
    "        W = W - .02 * update\n",
    "        \n",
    "    print sum(acc) / float(len(acc)), sum(losses)/len(losses)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
